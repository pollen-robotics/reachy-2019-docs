<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Introduction on Reachy manual</title><link>https://pollen-robotics.github.io/reachy-2019-docs/</link><description>Recent content in Introduction on Reachy manual</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://pollen-robotics.github.io/reachy-2019-docs/index.xml" rel="self" type="application/rss+xml"/><item><title>Install your robot</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/getting-started/install-your-robot/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/getting-started/install-your-robot/</guid><description>Install your robot Your Reachy is shipped already assembled and configured. It should be a matter of minutes before you start program it.
Before turning it on, it's always safer to check if you see anything unusual, in the unlikely event it has been damaged during transport. As an example, here is a box with a black Reachy with a single arm:
If you have a doubt, do not hesitate to send us a photo.</description></item><item><title>Connect to Your Robot</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/getting-started/connect-to-your-robot/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/getting-started/connect-to-your-robot/</guid><description>Connect to your robot Everything is already installed ðŸŽ‰ Reachy comes with a Raspberry-Pi 4 dedicated to its control. When you receive your Reachy, the board is pre-installed with all required softwares. So, you don't have to install anything on your computer.
This section is meant to:
let you know how to connect to the Raspberry-Pi, give you a bit more information on how things are actually working. First, you can find the Raspberry-Pi inside the trunk of the robot, as shown on this picture below.</description></item><item><title>Check the status of Reachy</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/getting-started/check-status/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/getting-started/check-status/</guid><description>Check the status of Reachy Check the mechanics Once connected, the next step is to check that everything is ok. The first thing to check is that the robot is ok. You should check that the arm are in a correct position, otherwise they may turn to go back to their base position and unplug a wire.
The base position of the arm looks like this:
TODO
You should also make sure the head is in a base position, meaning looking in front of it.</description></item><item><title>FAQ</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/getting-started/faq/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/getting-started/faq/</guid><description>FAQ Can I run the software on my own computer? Yes, most of it. Our main required dependency is USB to serial communication using the serial library. Yet, you will not have access to the camera or our vision primitive that relies on specific hardware (Raspberry-Pi camera and Google Coral TPU).
Where are the installed packages on the Raspberry-Pi? All python packages can be found in $HOME/dev.
Can I have multiple instances connected to the robot at the same time?</description></item><item><title>Safety First</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/posts/safety/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/posts/safety/</guid><description>Safety first compliance torque temperature limit initial position speed</description></item><item><title>Arm</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/technical-specifications/arm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/technical-specifications/arm/</guid><description>Reachy's arm specifications Weight repartition Overall Arm: 1670g Shoulder: 240g Upper arm: 610g Forearm: 590g Gripper: 230g Maximum payload: 500g
Of course, this may really vary depending on the holding and duration configuration.
Degrees of freedom Reachy's arm offers 7 degrees of movement + 1 for the gripper
Right Arm
Motor name Angle limits Motor ID shoulder_pitch -180, 90 10 shoulder_roll -180, 10 11 arm_yaw -90, 90 12 elbow_pitch -125, 0 13 forearm_yaw -100, 100 14 wrist_pitch -45, 45 15 wrist_roll -45, 45 16 gripper -69, 20 17 Left Arm</description></item><item><title>Gripper</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/technical-specifications/gripper/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/technical-specifications/gripper/</guid><description>Reachy's gripper specifications Animated by 1 Dynamixel AX-18A.
Includes a micro load cell 0.78 Kg</description></item><item><title>Head</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/technical-specifications/head/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/technical-specifications/head/</guid><description>Reachy's head specifications Reachyâ€™s head features two cameras: one to observe its environment and another camera to focus on the task of manipulating. The head is animated by Orbita, a unique technology developed by Pollen Robotics&amp;rsquo; R&amp;amp;D team. This ball joint actuator allows unpreceded dynamic and multi-directional movement. With animated antennas, Reachy can convey many emotions to his audience.
Coral development board G950-01456-01
See the head in action in this video: https://youtu.</description></item><item><title>Torso</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/technical-specifications/torso/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/technical-specifications/torso/</guid><description>Reachy's torso specifications Reachy's torso area includes the following elements :
Computer: RASPBERRY PI 4 2G MODEL B
Microphone: ReSpeaker Mic Array v2.0
TPU: Coral G950-01456-01
Speaker: Visaton VS-FRS7/8
Amplifier: Drocking PAM8620
Embedded PC
Power supply: power 180W - output 12V (input 110/120)</description></item><item><title>Instantiate Your Robot</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/program-your-robot/instantiate-your-robot/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/program-your-robot/instantiate-your-robot/</guid><description>Instantiate your robot The first step is to &amp;ldquo;instantiate&amp;rdquo; your robot. What we mean here, is that we will look for the different parts of your robot (connected via USBs on the Raspberry-Pi). We will identify them and check if all modules are connected.
We will also launch the synchronisation between the Raspberry-Pi and the different parts of your robot. The sensors value read from the robot will automatically be updated in your Python object.</description></item><item><title>Control The Arm</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/program-your-robot/control-the-arm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/program-your-robot/control-the-arm/</guid><description>Control the arm Once you have instantiated the Reachy object, you are actually connected to your robot. This means that the hardware (sensors and effectors) are synced with their software equivalent. This synchronization loop runs at about 100Hz. In particular, this lets you retrieve the arm(s) state and send commands to make it move.
Before actually running some commands, it's important to make sure you are ready:
Make sure the robot is in a &amp;ldquo;safe&amp;rdquo; state (as shown in the images below for instance).</description></item><item><title>Control The Head</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/program-your-robot/control-the-head/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/program-your-robot/control-the-head/</guid><description>Control the head The head is an important part of Reachy. It's where its camera are located and it participates a lot to the robot expressivity.
In the following sections, you will see how:
you can orient the head by controlling its neck, to move the antennas, and use its cameras. In the examples below, we will assume that you have already instantiated the head part of a Reachy as show in the section Instantiate Your Robot.</description></item><item><title>Pick and Place</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/program-your-robot/pick-and-place/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/program-your-robot/pick-and-place/</guid><description>Pick and Place Prepare Reachy workspace With all motors compliant try if you can realise the task you would like the robot to do. We will realise most of the recordings using physical demonstration.
Choose a good starting point Define a resting position Rest between motions. Real rest position (even turn the motor compliant if possible).
The rest position should not force! Static forcing is how the motors heat the fastest.</description></item><item><title>AI &amp; Coral TPU</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/program-your-robot/ai/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/program-your-robot/ai/</guid><description>AI &amp;amp; Google Coral TPU</description></item><item><title>Python's API</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/program-your-robot/python-api/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/program-your-robot/python-api/</guid><description>Python's API The whole Python's API is available here: https://pollen-robotics.github.io/reachy/.
The inline documentation can also be accessed directly from Python using instrospection. For instance:
In [1]: from reachy import Reachy In [2]: print(Reachy.__doc__) Class representing the connection with the hardware robot. Connect and synchronize with the hardware robot. Args: left_arm (reachy.parts.LeftArm): left arm part if present or None if absent right_arm (reachy.parts.RightArm): right arm part if present or None if absent head (reachy.</description></item><item><title>Setup The Demo</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/tictactoe/setup-the-demo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/tictactoe/setup-the-demo/</guid><description>Setup the demo On the ISO provided with the robot, the code to run the TicTacToe playground is already pre-installed. From your Raspberry-Pi board, you can find in the folder ~/dev/reachy-tictactoe.
Inside, you will find:
the code implementing the gameplay mechanisms, the specific assets: move trajectories, pre-trained vision network a service file to simplify launching Launch the demo at boot The easiest way to setup the demo is to launch it automatically at startup.</description></item><item><title>Playing With Reachy</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/tictactoe/playing-with-reachy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/tictactoe/playing-with-reachy/</guid><description>Playing with Reachy Unwrapping the demo Controlling the demo As you can see on the diagram, the demo runs in a fully autonomous way. Yet, they are a few way you can control and interact with it.
First, the robot will start a game only once the board is cleared. It is up to you to reset the board position and to put back the pawn to their base positions.</description></item><item><title>Train Your Own Vision Detection</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/tictactoe/train-your-own-detection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/tictactoe/train-your-own-detection/</guid><description>Train your own vision detection Take pictures of the board board, img = tp.reachy.analyze_board() Organize and get your data ready Train your classifier Use your own trained versions</description></item><item><title>Create your own virtual scene for Reachy</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/simulation/create-your-own-scene/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/simulation/create-your-own-scene/</guid><description>Create your own virtual scene for Reachy We've created a simulated version of our Reachy robot where we simulate its behaviour and motors physics. It comes as a Unity package with everything already setup.
This lets you create your own 3D Scene within Unity so you can build your own virtual experimental setup. You can add 3D objects with their physics (a table, objects that can be grasped and moved, etc).</description></item><item><title>Install from Scratch on a Raspberry-Pi</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/appendices/install-from-scratch-raspberry/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/appendices/install-from-scratch-raspberry/</guid><description>Install from Scratch on a Raspberry-Pi This guide describe how we generate our ISO. Its main use is for us to keep it up-to-date and always accessible for our team. You can freely use it and adapt it to your needs but we don't intend to explain every details here.
Prepare the Raspberry-Pi Burn an SD-Card (16Go or more) using Raspbian Buster with desktop - February 2020. Make sure to allow ssh (touch ssh on the boot partition) or directly work from the Pi board using a mouse, keyboard and screen.</description></item><item><title>Flash a Luos module</title><link>https://pollen-robotics.github.io/reachy-2019-docs/docs/appendices/flash-luos-module/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pollen-robotics.github.io/reachy-2019-docs/docs/appendices/flash-luos-module/</guid><description>Flash a Luos module To update the firmware of a Luos module, you need to re-flash it. Basically, this means re-writing its internal software.
It's a rather simple process but there is a few things to know.
The different modules, their firmware and their location First, you can find the modules location in the torso on the figure below:
TODO: schema avec l'emplacement des modules
Here is the different module present in each part and their associated firmware:</description></item></channel></rss>